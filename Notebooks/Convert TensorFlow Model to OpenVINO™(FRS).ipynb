{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f41fbb9",
   "metadata": {},
   "source": [
    "L'objectif ici est de convertir chacun de nos models avec Openvino afin que l'inférence soit plus rapide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd970cc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec952f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown\n",
    "from openvino.runtime import Core\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15edf7",
   "metadata": {},
   "source": [
    "### Model 1 : Car or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c09521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 03:20:42.449712: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-12 03:20:42.449737: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-12 03:20:46.196550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-12 03:20:46.196577: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-12 03:20:46.196619: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (liganium-HP): /proc/driver/nvidia/version does not exist\n",
      "2022-09-12 03:20:46.196795: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12 03:20:46.525501: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2022-09-12 03:20:46.550315: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2022-09-12 03:20:46.568117: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2022-09-12 03:20:46.722243: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2022-09-12 03:20:46.762158: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2022-09-12 03:20:47.764069: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: static/FRS_vgg/assets\n"
     ]
    }
   ],
   "source": [
    "#If you have a model in the HDF5 format, load the model using TensorFlow* 2\n",
    "# and serialize it in the SavedModel format.\n",
    "\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('static/FRS_vgg.h5')\n",
    "tf.keras.models.save_model(model,'static/FRS_vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805e485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mo --saved_model_dir static/carORnot_vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8d8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths of the source and converted models.\n",
    "model_path = Path(\"static/FRS_vgg\")\n",
    "ir_path = Path(\"static_openvino/FRS_vgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0bc66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static_openvino/FRS_vgg\n"
     ]
    }
   ],
   "source": [
    "print(ir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed3e98b",
   "metadata": {},
   "source": [
    "Convert a TensorFlow Model to OpenVINO IR Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc21e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer command to convert TensorFlow to OpenVINO:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "`mo --saved_model_dir \"static/FRS_vgg\" --input_shape \"[1,224,224,3]\" --framework tf --data_type FP16 --output_dir \"static_openvino/FRS_vgg\"`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct the command for Model Optimizer.\n",
    "# NB : on ne peut spécifier --input_model et --saved_model_dir en même temps\n",
    "mo_command = f\"\"\"mo\n",
    "                 --saved_model_dir \"{model_path}\"\n",
    "                 --input_shape \"[1,224,224,3]\" \n",
    "                 \n",
    "                 --framework tf\n",
    "                 --data_type FP16 \n",
    "                 --output_dir \"{ir_path}\"\n",
    "                 \"\"\"\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert TensorFlow to OpenVINO:\")\n",
    "display(Markdown(f\"`{mo_command}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8409742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting TensorFlow model to IR... This may take a few minutes.\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tNone\n",
      "\t- Path for generated IR: \t/home/liganium/Documents/Car Damage toolkit/Approche 1 Avec features_extraction et reglogistic/static_openvino/FRS_vgg\n",
      "\t- IR output name: \tsaved_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,224,224,3]\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "OpenVINO runtime found in: \t/home/liganium/anaconda3/lib/python3.9/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "Model Optimizer version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\ttensorflow: installed: 2.7.0, required: < 2.6\n",
      "\tnumpy: installed: 1.23.3, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev[tensorflow]\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/liganium/Documents/Car Damage toolkit/Approche 1 Avec features_extraction et reglogistic/static_openvino/FRS_vgg/saved_model.xml\n",
      "[ SUCCESS ] BIN file: /home/liganium/Documents/Car Damage toolkit/Approche 1 Avec features_extraction et reglogistic/static_openvino/FRS_vgg/saved_model.bin\n",
      "[ SUCCESS ] Total execution time: 25.14 seconds. \n",
      "[ SUCCESS ] Memory consumed: 1827 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n"
     ]
    }
   ],
   "source": [
    "# Run Model Optimizer if the IR model file does not exist\n",
    "if not ir_path.exists():\n",
    "    print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "    ! $mo_command\n",
    "else:\n",
    "    print(f\"IR model {ir_path} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdf49a",
   "metadata": {},
   "source": [
    "### Test Inference on the Converted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c9f534",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff77cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model = ie.read_model(model=str(ir_path) + \"/saved_model.xml\", weights=str(ir_path )+ \"/saved_model.bin\")\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e50b",
   "metadata": {},
   "source": [
    "### Get Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65916534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ConstOutput: names[input_1:0, Func/StatefulPartitionedCall/input/_0:0, input_1] shape{1,224,224,3} type: f32>\n",
      "<ConstOutput: names[StatefulPartitionedCall/model/dense_2/Softmax:0, StatefulPartitionedCall/Identity:0, Func/StatefulPartitionedCall/output/_39:0, Identity:0] shape{1,3} type: f32>\n",
      "{1, 224, 224, 3}\n"
     ]
    }
   ],
   "source": [
    "input_key = compiled_model.input(0)\n",
    "output_key = compiled_model.output(0)\n",
    "network_input_shape = input_key.shape\n",
    "\n",
    "print(input_key)\n",
    "print(output_key)\n",
    "print(network_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead4acb",
   "metadata": {},
   "source": [
    "### Load an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd073e",
   "metadata": {},
   "source": [
    "Load an image, resize it, and convert it to the input shape of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbd9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.applications.vgg19 import  preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bfb8782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b9ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img_224(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebe6aab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"static/7.jpg\"\n",
    "img = prepare_img_224(img_path)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7c4ea",
   "metadata": {},
   "source": [
    "### Do Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2adc2514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "result = compiled_model([img])[output_key]\n",
    "\n",
    "result_index = np.argmax(result)\n",
    "\n",
    "print(result)\n",
    "print(result_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d037d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REAR'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['FRONT','REAR','SIDE']\n",
    "labels[result_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
