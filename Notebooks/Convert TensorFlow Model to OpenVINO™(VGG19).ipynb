{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f41fbb9",
   "metadata": {},
   "source": [
    "L'objectif ici est de convertir chacun de nos models avec Openvino afin que l'inférence soit plus rapide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd970cc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec952f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 14:49:29.059357: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-13 14:49:29.059408: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from openvino.runtime import Core\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c15f3",
   "metadata": {},
   "source": [
    "Nous allons directement télécharger le VGG19 de openvino qui est optimisé pour le IR. Notons que ce VGG19 a été construit avec le framework caffe. Cela ne posera pas de problème bien que nous travaillons avec tensorflow car nous alons le convertir en IR qui est indépendante des frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b006b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: omz_downloader [-h] [--name PAT[,PAT...]] [--list FILE.LST] [--all]\r\n",
      "                      [--print_all] [--precisions PREC[,PREC...]] [-o DIR]\r\n",
      "                      [--cache_dir DIR] [--num_attempts N]\r\n",
      "                      [--progress_format {text,json}] [-j N]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --name PAT[,PAT...]   download only models whose names match at least one of\r\n",
      "                        the specified patterns\r\n",
      "  --list FILE.LST       download only models whose names match at least one of\r\n",
      "                        the patterns in the specified file\r\n",
      "  --all                 download all available models\r\n",
      "  --print_all           print all available models\r\n",
      "  --precisions PREC[,PREC...]\r\n",
      "                        download only models with the specified precisions\r\n",
      "                        (actual for DLDT networks); specify one or more of:\r\n",
      "                        FP32-INT1,FP32-INT8,FP16-INT1,FP32,FP16,FP16-INT8\r\n",
      "  -o DIR, --output_dir DIR\r\n",
      "                        path where to save models\r\n",
      "  --cache_dir DIR       directory to use as a cache for downloaded files\r\n",
      "  --num_attempts N      attempt each download up to N times\r\n",
      "  --progress_format {text,json}\r\n",
      "                        which format to use for progress reporting\r\n",
      "  -j N, --jobs N        how many downloads to perform concurrently\r\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader --h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d21cc75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading vgg19 ||################\n",
      "\n",
      "========== Downloading static/public/vgg19/vgg19.prototxt\n",
      "... 100%, 5 KB, 31828 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading static/public/vgg19/vgg19.caffemodel\n",
      "... 100%, 561202 KB, 4467 KB/s, 125 seconds passed\n",
      "\n",
      "========== Replacing text in static/public/vgg19/vgg19.prototxt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download vgg19\n",
    "! omz_downloader --name vgg19 -o static"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0693f8",
   "metadata": {},
   "source": [
    "La commande suite nous permettra d'obtenir la représentaion IR de notre model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eb7da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: omz_converter [-h] [-d DIR] [-o DIR] [--name PAT[,PAT...]]\r\n",
      "                     [--list FILE.LST] [--all] [--print_all]\r\n",
      "                     [--precisions PREC[,PREC...]] [-p PYTHON] [--mo MO.PY]\r\n",
      "                     [--add_mo_arg ARG] [--dry_run] [-j JOBS]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -d DIR, --download_dir DIR\r\n",
      "                        root of the directory tree with downloaded model files\r\n",
      "  -o DIR, --output_dir DIR\r\n",
      "                        root of the directory tree to place converted files\r\n",
      "                        into\r\n",
      "  --name PAT[,PAT...]   convert only models whose names match at least one of\r\n",
      "                        the specified patterns\r\n",
      "  --list FILE.LST       convert only models whose names match at least one of\r\n",
      "                        the patterns in the specified file\r\n",
      "  --all                 convert all available models\r\n",
      "  --print_all           print all available models\r\n",
      "  --precisions PREC[,PREC...]\r\n",
      "                        run only conversions that produce models with the\r\n",
      "                        specified precisions\r\n",
      "  -p PYTHON, --python PYTHON\r\n",
      "                        Python executable to run Model Optimizer with\r\n",
      "  --mo MO.PY            Model Optimizer entry point script\r\n",
      "  --add_mo_arg ARG      Extra argument to pass to Model Optimizer\r\n",
      "  --dry_run             Print the conversion commands without running them\r\n",
      "  -j JOBS, --jobs JOBS  number of conversions to run concurrently\r\n"
     ]
    }
   ],
   "source": [
    "! omz_converter --h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452dcfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Converting vgg19 to IR (FP16)\n",
      "Conversion command: /home/liganium/anaconda3/bin/python -- /home/liganium/anaconda3/bin/mo --framework=caffe --data_type=FP16 --output_dir=static_openvino/public/vgg19/FP16 --model_name=vgg19 --input=data '--mean_values=data[103.939,116.779,123.68]' --output=prob --input_model=static/public/vgg19/vgg19.caffemodel --input_proto=static/public/vgg19/vgg19.prototxt '--layout=data(NCHW)' '--input_shape=[1, 3, 224, 224]'\n",
      "\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/liganium/Documents/Car Damage toolkit/Approche 2 directement sans reglog/static/public/vgg19/vgg19.caffemodel\n",
      "\t- Path for generated IR: \t/home/liganium/Documents/Car Damage toolkit/Approche 2 directement sans reglog/static_openvino/public/vgg19/FP16\n",
      "\t- IR output name: \tvgg19\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tdata\n",
      "\t- Output layers: \tprob\n",
      "\t- Input shapes: \t[1, 3, 224, 224]\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tdata(NCHW)\n",
      "\t- Mean values: \tdata[103.939,116.779,123.68]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Path to Python Caffe* parser generated from caffe.proto: \t/home/liganium/anaconda3/lib/python3.9/site-packages/openvino/tools/mo/utils/../front/caffe/proto\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/liganium/Documents/Car Damage toolkit/Approche 2 directement sans reglog/static/public/vgg19/vgg19.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \t/home/liganium/anaconda3/lib/python3.9/site-packages/openvino/tools/mo/utils/../../extensions/front/caffe/CustomLayersMapping.xml\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "OpenVINO runtime found in: \t/home/liganium/anaconda3/lib/python3.9/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "Model Optimizer version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.23.3, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev[caffe]\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/liganium/Documents/Car Damage toolkit/Approche 2 directement sans reglog/static_openvino/public/vgg19/FP16/vgg19.xml\n",
      "[ SUCCESS ] BIN file: /home/liganium/Documents/Car Damage toolkit/Approche 2 directement sans reglog/static_openvino/public/vgg19/FP16/vgg19.bin\n",
      "[ SUCCESS ] Total execution time: 39.35 seconds. \n",
      "[ SUCCESS ] Memory consumed: 1732 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert vgg19 into IR\n",
    "! omz_converter --name vgg19 -d static -o static_openvino  --precisions FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdf49a",
   "metadata": {},
   "source": [
    "### Test Inference on the Converted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c9f534",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb9d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_path = Path(\"static_openvino/public/vgg19/FP16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff77cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model = ie.read_model(model=str(ir_path) + \"/vgg19.xml\", weights=str(ir_path )+ \"/vgg19.bin\")\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e50b",
   "metadata": {},
   "source": [
    "### Get Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65916534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ConstOutput: names[data] shape{1,3,224,224} type: f32>\n",
      "<ConstOutput: names[prob] shape{1,1000} type: f32>\n",
      "{1, 3, 224, 224}\n"
     ]
    }
   ],
   "source": [
    "input_key = compiled_model.input(0)\n",
    "output_key = compiled_model.output(0)\n",
    "network_input_shape = input_key.shape\n",
    "\n",
    "print(input_key)\n",
    "print(output_key)\n",
    "print(network_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead4acb",
   "metadata": {},
   "source": [
    "### Load an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd073e",
   "metadata": {},
   "source": [
    "Load an image, resize it, and convert it to the input shape of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbd9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.applications.vgg19 import  preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b9ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img_224(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebe6aab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "(1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "img_path = \"static/7.jpg\"\n",
    "img = prepare_img_224(img_path)\n",
    "print(img.shape)\n",
    "img1 = np.reshape(img,(1,3,224,224))\n",
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef60300",
   "metadata": {},
   "source": [
    "### Do Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b4e6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "result = compiled_model([img1])[output_key]\n",
    "\n",
    "print(result.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
